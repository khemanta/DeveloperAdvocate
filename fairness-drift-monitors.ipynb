{
    "cells": [
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Model Fairness, Explainability and Drift with Watson OpenScale\n\nThis notebook should be run in a Watson Studio project, using Default Python 3.6 runtime environment. It requires service credentials and a Cloud API key to access the following Cloud services:\n* Watson Machine Learning\n* Watson OpenScale\n\nThe notebook will configure several monitors in OpenScale for the German Credit Risk model. The notebook assumes the model has been created/deployed to Watson Machine Learning and that the subscription has been created in Watson OpenScale."
        },
        {
            "metadata": {
                "collapsed": true
            },
            "cell_type": "markdown",
            "source": "#### Dependency Setup"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!pip install --upgrade ibm-ai-openscale --no-cache | tail -n 1\n!pip install --upgrade watson-machine-learning-client | tail -n 1",
            "execution_count": 1,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->ibm-ai-openscale) (1.24.1)\nRequirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from ibm-cos-sdk-core==2.*,>=2.0.0->ibm-cos-sdk->watson-machine-learning-client) (0.9.3)\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import pandas as pd\nimport json\nimport random\n\nfrom IPython.utils import io\n\nfrom watson_machine_learning_client import WatsonMachineLearningAPIClient\n\nfrom ibm_ai_openscale import APIClient\nfrom ibm_ai_openscale.engines import *\nfrom ibm_ai_openscale.utils import *\nfrom ibm_ai_openscale.supporting_classes import PayloadRecord, Feature\nfrom ibm_ai_openscale.supporting_classes.enums import *",
            "execution_count": 2,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "#### Configure Service Credentials\n\nUpdate the two cells below with your Cloud API Key and your Watson Machine Learning service credentials."
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "CLOUD_API_KEY=\"WRSbGHmNSHvy-tLXNfqRvPhnGFfGfx6aLZnVv05h7PsQ\"",
            "execution_count": 3,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "WML_CREDENTIALS = {\n  \"apikey\": \"Rk2Chr1ij8WCQgMThbYME0-o28aa2nwtrAMH7eMspYJP\",\n  \"iam_apikey_description\": \"Auto-generated for key 1cbdf600-c774-449f-8d7d-3ab37b1a793f\",\n  \"iam_apikey_name\": \"Service credentials-1\",\n  \"iam_role_crn\": \"crn:v1:bluemix:public:iam::::serviceRole:Writer\",\n  \"iam_serviceid_crn\": \"crn:v1:bluemix:public:iam-identity::a/44f657e1cfa9244c30605fcaaa86343a::serviceid:ServiceId-7aa04496-3655-4f42-856e-80957aa89bf6\",\n  \"instance_id\": \"ead3646b-8ad5-4505-80e7-ff0afafe895b\",\n  \"url\": \"https://us-south.ml.cloud.ibm.com\"\n}",
            "execution_count": 4,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "#### Model Parameters\n\nWe use the same name for the Scikit model and the deployment to WML.\n\n__Ensure that the two parameters match the model / deployment you have previously subscribed__"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "MODEL_NAME = \"Spark German Risk Model\"\nDEPLOYMENT_NAME = \"Spark German Risk Deployment\"",
            "execution_count": 5,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "#### Load Training Data\n\nAlthough we have are not creating a model at this point, Watson OpenScale makes use of statistics gathered from the training data for various monitors. "
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "with io.capture_output() as captured:\n    !wget https://raw.githubusercontent.com/pmservice/ai-openscale-tutorials/master/assets/historical_data/german_credit_risk/wml/german_credit_data_biased_training.csv  -O german_credit_data_biased_training.csv\n    \n!ls -lh german_credit_data_biased_training.csv\n\ndata_df = pd.read_csv('german_credit_data_biased_training.csv', sep=\",\", header=0)\n#data_df.head()",
            "execution_count": 6,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "-rw-r----- 1 dsxuser dsxuser 674K Nov 23 17:17 german_credit_data_biased_training.csv\r\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "#### Gather Model Information"
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "wml_client = WatsonMachineLearningAPIClient(WML_CREDENTIALS)\nwml_client.repository.list_models()\n\nmodel_uid = None\nwml_models = wml_client.repository.get_details()\nfor model_in in wml_models['models']['resources']:\n    if MODEL_NAME == model_in['entity']['name']:\n        model_uid = model_in['metadata']['guid']\n        break\n\ndeployment_uid = None\ndeployment = None\nscoring_url = None\nwml_deployments = wml_client.deployments.get_details()\nfor deployment_in in wml_deployments['resources']:\n    if DEPLOYMENT_NAME == deployment_in['entity']['name']:\n        deployment_uid = deployment_in['metadata']['guid']\n        scoring_url = deployment_in['entity']['scoring_url']\n        deployment = deployment_in\n        break\n\nif model_uid is None:\n    print(\"No model ...\")\n    \nif deployment_uid is None:\n    print(\"No Model deployment...\")\n    \nprint(\"Model id: {}\".format(model_uid))\nprint(\"Deployment id: {}\".format(deployment_uid))\nprint(\"Scoring URL: {}\".format(scoring_url))",
            "execution_count": 7,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "------------------------------------  -----------------------  ------------------------  ---------\nGUID                                  NAME                     CREATED                   FRAMEWORK\ne7e5151c-670f-4511-9756-934a0f3ebea3  Spark German Risk Model  2019-11-23T07:04:59.246Z  mllib-2.3\n------------------------------------  -----------------------  ------------------------  ---------\nModel id: e7e5151c-670f-4511-9756-934a0f3ebea3\nDeployment id: 5bea19b8-2ae7-4ce1-8df0-a09148a1485a\nScoring URL: https://us-south.ml.cloud.ibm.com/v3/wml_instances/ead3646b-8ad5-4505-80e7-ff0afafe895b/deployments/5bea19b8-2ae7-4ce1-8df0-a09148a1485a/online\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Fairness and Explainability Monitors"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "#### Get Watson OpenScale GUID\nEach instance of OpenScale has a unique ID. We can get this value using the Cloud API key specified at the beginning of the notebook."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "wos_client = None\nWOS_GUID = get_instance_guid(api_key=CLOUD_API_KEY)\nWOS_CREDENTIALS = {\n    \"instance_guid\": WOS_GUID,\n    \"apikey\": CLOUD_API_KEY,\n    \"url\": \"https://api.aiopenscale.cloud.ibm.com\"\n}\n\nif WOS_GUID is None:\n    print('Watson OpenScale GUID NOT FOUND')\nelse:\n    print(\"Watson OpenScale GUID: {}\".format(WOS_GUID))\n\n    \nwos_client = APIClient(aios_credentials=WOS_CREDENTIALS)\nprint(\"Watson OpenScale Python Client Version: {}\".format(wos_client.version))",
            "execution_count": 8,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Watson OpenScale GUID: 0ac203a2-114a-497a-9721-d2dedf99d339\nWatson OpenScale Python Client Version: 2.1.19\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "#### Get subscription\n\nWe have previously subscribed Watson OpenScale to our machine learning model. Here we get that subscription."
        },
        {
            "metadata": {
                "scrolled": false
            },
            "cell_type": "code",
            "source": "wos_client.data_mart.subscriptions.list()\n\nsubscriptions_uids = wos_client.data_mart.subscriptions.get_uids()\nsubscription_id = None\nfor sub in subscriptions_uids:\n    if wos_client.data_mart.subscriptions.get_details(sub)['entity']['asset']['name'] == MODEL_NAME:\n        subscription = wos_client.data_mart.subscriptions.get(sub)\n        subscription_id = sub\n        break\n            \nif subscription is None:\n    print('Subscription not found.')\n    \nprint(\"Subscription ID: {}\".format(subscription_id))\n#print(json.dumps(wos_client.data_mart.subscriptions.get_details(subscription_id),indent=2))",
            "execution_count": 9,
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "<IPython.core.display.HTML object>",
                        "text/html": "<HTML>\n        <body>\n            <h3>Subscriptions</h3>\n            <table style='border: 1px solid #dddddd; font-family: Courier'>\n                <th style='border: 1px solid #dddddd'>uid</th><th style='border: 1px solid #dddddd'>name</th><th style='border: 1px solid #dddddd'>type</th><th style='border: 1px solid #dddddd'>binding_uid</th><th style='border: 1px solid #dddddd'>created</th>\n                <tr><td style='border: 1px solid #dddddd'>5a11528d-f2ae-4b8f-9f03-08fb90587d1a</td><td style='border: 1px solid #dddddd'>Spark German Risk Model</td><td style='border: 1px solid #dddddd'>model</td><td style='border: 1px solid #dddddd'>ead3646b-8ad5-4505-80e7-ff0afafe895b</td><td style='border: 1px solid #dddddd'>2019-11-23T07:07:04.924Z</td></tr>\n            </table>\n        </body>\n        </HTML>"
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "text": "Subscription ID: 5a11528d-f2ae-4b8f-9f03-08fb90587d1a\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Enable Fairness Monitor\n\nThe code below configures fairness monitoring for our model. It turns on monitoring for two features, Sex and Age. In each case, we must specify:\n  * Which model feature to monitor\n  * One or more **majority** groups, which are values of that feature that we expect to receive a higher percentage of favorable outcomes\n  * One or more **minority** groups, which are values of that feature that we expect to receive a higher percentage of unfavorable outcomes\n  * The threshold at which we would like OpenScale to display an alert if the fairness measurement falls below (in this case, 95%)\n\nAdditionally, we must specify which outcomes from the model are favourable outcomes, and which are unfavourable. We must also provide the number of records OpenScale will use to calculate the fairness score. In this case, OpenScale's fairness monitor will run hourly, but will not calculate a new fairness rating until at least 200 records have been added. Finally, to calculate fairness, OpenScale must perform some calculations on the training data, so we provide the dataframe containing the data."
        },
        {
            "metadata": {
                "scrolled": false
            },
            "cell_type": "code",
            "source": "subscription.fairness_monitoring.enable(\n            features=[\n                Feature(\"Sex\", majority=['male'], minority=['female'], threshold=0.95),\n                Feature(\"Age\", majority=[[26,75]], minority=[[18,25]], threshold=0.95)\n            ],\n            favourable_classes=['No Risk'],\n            unfavourable_classes=['Risk'],\n            min_records=200,\n            training_data=data_df\n        )",
            "execution_count": 10,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Enable Drift Monitoring\n\nWe will now enable drift monitoring that will run when there are 100 records and set a threshold of 10% degradation in performance. The code will then poll until the drift monitoring is configured."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "subscription.drift_monitoring.enable(min_records=100, threshold=0.1)\n\ndrift_status = None\nwhile drift_status != 'finished':\n    drift_details = subscription.drift_monitoring.get_details()\n    drift_status = drift_details['parameters']['config_status']['state']\n    if drift_status != 'finished':\n        print(datetime.utcnow().strftime('%H:%M:%S'), drift_status)\n        time.sleep(30)\nprint(\"Drift status: {}\".format(drift_status)",
            "execution_count": 11,
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "SyntaxError",
                    "evalue": "unexpected EOF while parsing (<ipython-input-11-3a2e71330b39>, line 10)",
                    "traceback": [
                        "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-3a2e71330b39>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    print(\"Drift status: {}\".format(drift_status)\u001b[0m\n\u001b[0m                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
                    ]
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Send Requests to Model \n\nNow that we have some model monitors enabled, we will send some scoring requests through our model. This next section randomly selects 200 records from the data feed and sends those records to the model for predictions. This is enough to exceed the minimum threshold for records set in the previous section, which allows OpenScale to begin calculating fairness and drift."
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "with io.capture_output() as captured:\n    !wget https://raw.githubusercontent.com/pmservice/ai-openscale-tutorials/master/assets/historical_data/german_credit_risk/wml/german_credit_feed.json -O german_credit_feed.json\n!ls -lh german_credit_feed.json\n   \nwith open('german_credit_feed.json', 'r') as scoring_file:\n    scoring_data = json.load(scoring_file)\n\nfields = scoring_data['fields']\nvalues = []\nfor _ in range(200):\n    values.append(random.choice(scoring_data['values']))\npayload_scoring = {\"fields\": fields, \"values\": values}\n\nscoring_response = wml_client.deployments.score(scoring_url, payload_scoring)\n\nprint('Number of scoring result:', len(scoring_response['values']))\ntime.sleep(10)\nprint('Number of records in payload table: ', subscription.payload_logging.get_records_count())",
            "execution_count": 12,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "-rw-r----- 1 dsxuser dsxuser 3.0M Nov 23 17:19 german_credit_feed.json\nNumber of scoring result: 200\nNumber of records in payload table:  208\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "__Note:__ The number of records in the payload table below should be 208 (the 200 scoring requests made above and the initial 8 scoring requests sent prior to monitor configuration). "
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "print('Number of records in payload table: ', subscription.payload_logging.get_records_count())\n#subscription.payload_logging.show_table(limit=20)",
            "execution_count": 13,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Number of records in payload table:  208\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Run fairness monitor\n\nKick off a fairness monitor run on current data. The monitor runs hourly, but can be manually initiated using the Python client, the REST API, or the graphical user interface."
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "run_details = subscription.fairness_monitoring.run(background_mode=False)",
            "execution_count": 14,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "\n\n=======================================================================\n\n Counting bias for deployment_uid=5bea19b8-2ae7-4ce1-8df0-a09148a1485a \n\n=======================================================================\n\n\n\nRUNNING......\nFINISHED\n\n---------------------------\n Successfully finished run \n---------------------------\n\n\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "time.sleep(10)\nsubscription.fairness_monitoring.show_table()",
            "execution_count": 15,
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "<IPython.core.display.HTML object>",
                        "text/html": "<HTML>\n        <body>\n            <h3>FairnessMetrics (binding_id=ead3646b-8ad5-4505-80e7-ff0afafe895b, subscription_id=5a11528d-f2ae-4b8f-9f03-08fb90587d1a)</h3>\n            <table style='border: 1px solid #dddddd; font-family: Courier'>\n                <th style='border: 1px solid #dddddd'>ts</th><th style='border: 1px solid #dddddd'>feature</th><th style='border: 1px solid #dddddd'>feature_value</th><th style='border: 1px solid #dddddd'>fairness_biased</th><th style='border: 1px solid #dddddd'>fairness_value</th><th style='border: 1px solid #dddddd'>fairness_fav_class</th><th style='border: 1px solid #dddddd'>binding_id</th><th style='border: 1px solid #dddddd'>subscription_id</th><th style='border: 1px solid #dddddd'>asset_revision</th><th style='border: 1px solid #dddddd'>deployment_id</th><th style='border: 1px solid #dddddd'>process</th>\n                <tr><td style='border: 1px solid #dddddd'>2019-11-23 17:31:31.668657+00:00</td><td style='border: 1px solid #dddddd'>Sex</td><td style='border: 1px solid #dddddd'>female</td><td style='border: 1px solid #dddddd'>True</td><td style='border: 1px solid #dddddd'>0.907</td><td style='border: 1px solid #dddddd'>68.5</td><td style='border: 1px solid #dddddd'>ead3646b-8ad5-4505-80e7-ff0afafe895b</td><td style='border: 1px solid #dddddd'>5a11528d-f2ae-4b8f-9f03-08fb90587d1a</td><td style='border: 1px solid #dddddd'>5a11528d-f2ae-4b8f-9f03-08fb90587d1a</td><td style='border: 1px solid #dddddd'>5bea19b8-2ae7-4ce1-8df0-a09148a1485a</td><td style='border: 1px solid #dddddd'></td></tr><tr><td style='border: 1px solid #dddddd'>2019-11-23 17:31:31.668657+00:00</td><td style='border: 1px solid #dddddd'>Age</td><td style='border: 1px solid #dddddd'>[18, 25]</td><td style='border: 1px solid #dddddd'>False</td><td style='border: 1px solid #dddddd'>1.087</td><td style='border: 1px solid #dddddd'>81.0</td><td style='border: 1px solid #dddddd'>ead3646b-8ad5-4505-80e7-ff0afafe895b</td><td style='border: 1px solid #dddddd'>5a11528d-f2ae-4b8f-9f03-08fb90587d1a</td><td style='border: 1px solid #dddddd'>5a11528d-f2ae-4b8f-9f03-08fb90587d1a</td><td style='border: 1px solid #dddddd'>5bea19b8-2ae7-4ce1-8df0-a09148a1485a</td><td style='border: 1px solid #dddddd'></td></tr>\n            </table>\n        </body>\n        </HTML>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Run drift monitor\n\nKick off a drift monitor run on current data. The monitor runs every hour to compare transaction data against training data patterns. We can be manually initiate this using the Python client, the REST API, or the graphical user interface."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "drift_run_details = subscription.drift_monitoring.run(background_mode=False)",
            "execution_count": 18,
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "KeyError",
                    "evalue": "'parameters'",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-18-9c1e095ebb70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdrift_run_details\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubscription\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrift_monitoring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackground_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/ibm_ai_openscale/base_classes/configuration/drift_monitoring.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, background_mode)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \"\"\"\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         response = self._ai_client.requests_session.post(\n",
                        "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/ibm_ai_openscale/base_classes/configuration/drift_monitoring.py\u001b[0m in \u001b[0;36m_wait_for_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wait_for_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_configuration_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'finished'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/ibm_ai_openscale/base_classes/configuration/drift_monitoring.py\u001b[0m in \u001b[0;36m_get_configuration_state\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_configuration_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mdetails\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config_status'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'train_drift_model_stage'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mKeyError\u001b[0m: 'parameters'"
                    ]
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "time.sleep(10)\nsubscription.drift_monitoring.get_table_content()",
            "execution_count": 19,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 19,
                    "data": {
                        "text/plain": "Empty DataFrame\nColumns: [ts, id, measurement_id, value, lower limit, upper limit, tags, binding_id, subscription_id, deployment_id]\nIndex: []",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ts</th>\n      <th>id</th>\n      <th>measurement_id</th>\n      <th>value</th>\n      <th>lower limit</th>\n      <th>upper limit</th>\n      <th>tags</th>\n      <th>binding_id</th>\n      <th>subscription_id</th>\n      <th>deployment_id</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Next steps\n\nWe can now monitor the model or configure some of the other monitors (quality, fairness, explainability, drift, etc) using either the UI or through a python client.\n\n__Return to the workshop instruction book.__\n\n\n## Credits\n\nThis notebook was adapted from the following sources:\n\n* [Monitor Models Code Pattern](https://github.com/IBM/monitor-wml-model-with-watson-openscale)\n* [OpenScale Labs](https://github.com/pmservice/OpenScale-Labs)\n* [OpenScale Tutorials](https://github.com/pmservice/ai-openscale-tutorials)\n\n#### Original Authors\n* Eric Martens, is a technical specialist having expertise in analysis and description of business processes, and their translation into functional and non-functional IT requirements. He acts as the interpreter between the worlds of IT and business.\n* Lukasz Cmielowski, PhD, is an Automation Architect and Data Scientist at IBM with a track record of developing enterprise-level applications that substantially increases clients' ability to turn data into actionable knowledge."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.6",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.6.8",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}